{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}},"colab":{"name":"04_device.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"MUlbCg3yAayF","colab_type":"code","colab":{}},"source":["# default_exp gpu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjR3Eky7AYNU","colab_type":"code","colab":{}},"source":["#hide\n","#test_flag_colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMk1xHfLAvps","colab_type":"code","colab":{}},"source":["#hide\n","!pip install nbdev\n","!pip install fastcore"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJxP1pdTQ0t4","colab_type":"code","colab":{}},"source":["#hide\n","%cd /content/drive/My\\ Drive/mx_utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hijn2gzzA5ej","colab_type":"code","colab":{}},"source":["#hide\n","#test_flag_imports\n","from nbdev import * \n","from nbdev.showdoc import *\n","from fastcore.test import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDmFL3to_oYJ","colab_type":"text"},"source":["# Device\n","\n","> GPU and device related code\n"]},{"cell_type":"markdown","metadata":{"id":"Tn6G7wexdWn4","colab_type":"text"},"source":["## GPU"]},{"cell_type":"code","metadata":{"id":"7ZJbKSp4bg3F","colab_type":"code","colab":{}},"source":["#exports\n","def versions():\n","  \"Checks if GPU enabled and if so displays device details with cuda, pytorch, fastai versions\"\n","  print(\"GPU: \", torch.cuda.is_available())\n","  if torch.cuda.is_available() == True:\n","    print(\"Device = \", torch.device(torch.cuda.current_device()))\n","    print(\"Cuda version - \", torch.version.cuda)\n","    print(\"cuDNN version - \", torch.backends.cudnn.version())\n","    print(\"PyTorch version - \", torch.__version__)\n","    print(\"fastai version\", fastai.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TN1Zb3lU8Ir6","colab_type":"text"},"source":["Use `!nvidia-smi` to get GPU details and current memory usage."]},{"cell_type":"markdown","metadata":{"id":"B38CKxzm8klg","colab_type":"text"},"source":["`torch.cuda.empty_cache()` clears GPU cache to free up GPU memory"]}]}
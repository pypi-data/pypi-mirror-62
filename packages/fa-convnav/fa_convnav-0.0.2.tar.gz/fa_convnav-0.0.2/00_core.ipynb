{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"00_core.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"kiewtiyZRsT1","colab_type":"code","colab":{}},"source":["# default_exp core"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vC1EcZLaRzrq","colab_type":"code","colab":{}},"source":["#hide\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xgrs9cGRR0iJ","colab_type":"code","colab":{}},"source":["#hide\n","!pip install nbdev\n","!pip install fastcore"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8CxCNq3cx6v","colab_type":"code","colab":{}},"source":["#hide\n","#required for the tests using previously saved learner\n","try:\n","  import fastai2.basics\n","except:\n","  !pip install fastai2\n","else:\n","  print('fastai2 already installed')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfv0pWHTR32x","colab_type":"code","colab":{}},"source":["#hide\n","% cd /content/drive/My\\ Drive/fa_convnav"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUBUz5tdepqM","colab_type":"code","colab":{}},"source":["#hide\n","from fastai2.basics import *\n","from fastai2.callback.all import *\n","from fastai2.vision.all import *\n","from torch import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEboL3EOR7C7","colab_type":"code","colab":{}},"source":["#hide\n","#not deps but we need them to use nbdev and run tests\n","from nbdev import * \n","from nbdev.showdoc import *\n","from fastcore.test import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_sbnKozZppj","colab_type":"code","colab":{}},"source":["#hide\n","def get_test_vars():\n","  #load test_vars from file if not already downloaded\n","  try:\n","    test_learner\n","  except:\n","    with gzip.open(\"test_learner_resnet18\", \"rb\") as f:\n","      test_learner = pickle.load(f)\n","    with gzip.open(\"test_summary_resnet18\", \"rb\") as f:\n","      test_summary = pickle.load(f)\n","  try:\n","    test_df\n","  except:\n","    with gzip.open(\"test_df_resnet18\", \"rb\") as f:\n","      test_df = pickle.load(f)\n","  return test_learner, test_summary, test_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NjpXoatXRsT7","colab_type":"text"},"source":["# Core\n","\n","> Core functionality for fa_convnav"]},{"cell_type":"code","metadata":{"id":"aoylco3JZAHV","colab_type":"code","colab":{}},"source":["#export\n","import gzip, pickle\n","from dataclasses import dataclass\n","from pandas import DataFrame, option_context\n","from fa_convnav.models import models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PZGwUQPNnOm","colab_type":"code","colab":{}},"source":["#export\n","def find_model(n): \n","    \"Returns tuple of model type and name (e.g. ('resnet', 'resnet50')) given `n`, the number of named_modules in Learner.model.named_modules()\"\n","    for d in models:\n","      match = [(k, m) for k, v in d.items() for m, l in v if l == n]\n","      if match != []: break\n","    if len(match) > 0: return match[0] # (model_type, model_name)\n","    assert True, 'Model not supported. Use `supported_models()` to get a list of supported models.'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JDSdiBul7SCD","colab_type":"code","colab":{}},"source":["test_eq(find_model(162), ('resnet', 'resnet50'))\n","test_eq(find_model(585), ('densenet', 'densenet161'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ato6zqsWF-5l","colab_type":"code","colab":{}},"source":["#export\n","def get_row(l, m):\n","  \"Construct dataframe row from `l` (Learner.named_modules() module) and `m` (model_type)\"\n","\n","  # create generic row data from `l` (model.named_module() layer) and `m` (model_type)\n","  lyr_name = l[0]\n","  lyr_obj = l[1]\n","  ln_split = str(lyr_name).split('.', 4)\n","  ln_n_splits = len(ln_split)\n","  lyr_str = str(lyr_obj)\n","\n","  tch_cls_str = str(type(lyr_obj))\n","  tch_cls_substr =  tch_cls_str[tch_cls_str.find(\"<class\")+8: tch_cls_str.find(\">\")-1]\n","  tch_cls = tch_cls_substr.split('.')[-1]\n","\n","  div = tch_cls if lyr_name == '0' or lyr_name == '1' else ''\n","  mod = tch_cls if ln_n_splits == 2 else ''\n","  blk = tch_cls if ln_n_splits == 3 and not lyr_name.startswith('1') else ''\n","  lyr = lyr_str[:90]\n","\n","  # customise generic row for peculiarities of specific models\n","  if m == 'vgg' or m == 'alexnet':\n","    if ln_n_splits >2: ln_split[2] = '' \n","    blk = ''\n","\n","  elif m == 'squeezenet':\n","     blk = tch_cls if ln_n_splits == 3 and tch_cls == 'Fire' else '' \n","     if blk == 'Fire': lyr = ''   \n","\n","  elif m == 'resnet':\n","    if blk == 'BasicBlock' or blk == 'Bottleneck': lyr = ''\n","    else:\n","      if ln_n_splits > 4: lyr = f\". . {lyr_str[:86]}\" \n","      if ln_n_splits == 4 and ln_split[3] == 'downsample': lyr = f'Container{tch_cls}'\n","       \n","  elif m == 'densenet':\n","    lyr_name = lyr_name.replace('denseblock', '').replace('denselayer', '')\n","    ln_split = str(lyr_name).split('.', 5)\n","    if len(ln_split) > 1 and ln_split[0] != '1': del ln_split[1] \n","    ln_n_splits = len(ln_split)\n","\n","    mod = tch_cls if (lyr_name.startswith('0') and ln_n_splits == 2) or (lyr_name.startswith('1') and ln_n_splits == 2) else ''\n","    blk = tch_cls if ln_n_splits == 3 and tch_cls == '_DenseLayer' else '' \n","    if mod == '_DenseBlock' or mod == '_Transition' or blk == '_DenseLayer': \n","      lyr = ''\n","    else: \n","      if lyr_name == '0' or lyr_name == '1': div = tch_cls \n","      if lyr_name == '0.0': div = f'. . {tch_cls}'\n","      \n","  elif m == 'xresnet':\n","    blk = tch_cls if ln_n_splits == 3 and tch_cls == 'ResBlock' else '' \n","    if mod == 'ConvLayer' or blk == 'ResBlock': \n","      lyr = ''\n","    else:\n","      if ln_n_splits < 4: lyr =  lyr_str[:90]\n","      elif ln_n_splits == 4 and tch_cls == 'Sequential': lyr =  f'Container{tch_cls}'\n","      elif ln_n_splits == 4 and tch_cls == 'ReLU': lyr =  lyr_str[:90]\n","      elif ln_n_splits == 5 and tch_cls == 'ConvLayer': lyr =  f'. . Container{tch_cls}'\n","      else: lyr =  f'. . . . {lyr_str[:32]}'\n","\n","  else:\n","    raise Exception(\"Model type not recognised\")\n","  \n","  return {\n","      'Module_name': lyr_name, \n","      'Model': tch_cls if lyr_name == '' else '',\n","      'Division': div,\n","      'Container_child': mod,\n","      'Container_block': blk, \n","      'Layer_description': lyr,\n","      'Torch_class': tch_cls_substr,\n","      'Output_dimensions': '',\n","      'Parameters': '',\n","      'Trainable': '',\n","      'Currently': '',\n","      'div_id': ln_split[0] if ln_n_splits >0 else '',  \n","      'chd_id': ln_split[1] if ln_n_splits >1 else '',  \n","      'blk_id': ln_split[2] if ln_n_splits >2 else '',\n","      'lyr_id': ln_split[3] if ln_n_splits >3 else '',\n","      'tch_cls': tch_cls,\n","      'out_dim': '',\n","      'current': '',\n","      'lyr_blk': '', \n","      'lyr_chd': '',\n","      'blk_chd': '',\n","      'lyr_obj': lyr_obj\n","      }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eETWLnQ5lwmN","colab_type":"code","colab":{}},"source":["test_learner, _, _ = get_test_vars()\n","module5 = list(test_learner.model.named_modules())[5]\n","module_last = list(test_learner.model.named_modules())[-1]\n","\n","test_eq(get_row(module5, 'resnet')['Module_name'], '0.3')\n","test_eq(get_row(module_last, 'resnet')['Layer_description'], 'Linear(in_features=512, out_features=37, bias=False)')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ni1wThjIOdT","colab_type":"text"},"source":["## Utilities"]},{"cell_type":"code","metadata":{"id":"ybXsZPgmHC_S","colab_type":"code","colab":{}},"source":["#export\n","def supported_models():\n","  \"Prints list of models supported by fa_convnav (models.ipynb contains list of currently supported models).\"\n","  print('Supported models')\n","  print('================\\n')\n","  for d in models:\n","      [[print(m) for m, l in v] for k, v in d.items()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rXFC8rcJsrd1","colab_type":"code","colab":{}},"source":["#export\n","def get_inp_sz(infos):\n","  \"Slice first row of `infos` to give string representation of model input sizes \"\n","  inp_sz = infos[0]\n","  inp_sz_str = inp_sz[inp_sz.find(\"['\")+2:inp_sz.find(\"']\")] \n","  return inp_sz_str"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9vpwF-BX7yxL","colab_type":"code","colab":{}},"source":["test_eq(get_inp_sz([\"Sequential (Input shape: ['128 x 3 x 224 x 224'])\"]), \"128 x 3 x 224 x 224\" )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLWSum9Eq_OJ","colab_type":"code","colab":{}},"source":["#export\n","def infos_to_gen(infos):\n","  \"Slice the remaining rows of `infos` to give the layers, `m`, output dimensions `o`, parameters `p`, and trainable `t` of each layer and return (m,o,p,t) for all layers in a generator\"\n","  lyr_info = infos[4:-17][::2]\n","  info_list = []\n","  for l in lyr_info:\n","    m, *s, p, t = [y for y in l.split(' ') if y !=\"\"]\n","    info_list.append((m, f\"[{' '.join(s)}]\", p, t))\n","  return (i for i in info_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ul5DgprG91Sp","colab_type":"code","colab":{}},"source":["_, test_summary, _ = get_test_vars()\n","gen = infos_to_gen(test_summary.split('\\n'))\n","test_eq(next(gen), ('Conv2d', '[128 x 64 x 112 x 11]', '9,408', 'False'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sH5zWKeYFYyX","colab":{}},"source":["#export\n","@dataclass\n","class CNDF:\n","  \"Compile information from fastai `Learner.model` and 'layer_info(Learner)` into a dataframe\"\n","  learner: any\n","  learner_summary: str\n","\n","  def __post_init__(self):\n","    assert hasattr(self.learner, 'model'), \"Invalid learner: no 'model' attribute\"\n","    self.model = self.learner.model                                         # fastai `Learner.model` object\n","    self.layers = list(self.learner.model.named_modules())                  # fastai `named_modules` method\n","    self.num_layers = len(self.layers)                    \n","    self.model_type, self.model_name = find_model(self.num_layers)\n","\n","    infos_split = self.learner_summary.split('\\n')                         # fastai `Learner.summary()` string\n","    self.inp_sz = get_inp_sz(infos_split)\n","    self.bs = self.inp_sz[0]\n","    info_gen = infos_to_gen(infos_split)\n","               \n","    # create base dataframe `df` from a list of formatted rows in `layers`\n","    df = DataFrame([get_row(l, self.model_type) for l in self.layers]) \n","\n","    # remove layer descriptions from container rows\n","    df.at[0, 'Layer_description'] = ''\n","    df.loc[(df['Division'].str.contains('Sequential')) | \\\n","          (df['Container_child'] == 'Sequential') | \\\n","          (df['Container_child'] == 'AdaptiveConcatPool2d'), 'Layer_description'] = ''\n","\n","    for row in df.itertuples(): \n","      idx = row.Index\n","      if row.Layer_description not in {'', '. . ContainerConvLayer', 'ContainerSequential'}:\n","        _, o, p, t = next(info_gen)\n","        df.at[idx, 'Output_dimensions'] = str(o)\n","        df.at[idx, 'Parameters'] =  p\n","        df.at[idx, 'Trainable'] = t\n","        if 'Conv2d' in row.Torch_class:\n","          df.at[idx, 'Currently'] = 'Unfrozen' if t == 'True' else 'Frozen'\n","\n","    # backfill container rows with summary layer information and layer/block counts\n","    # 1.set up index stores and counters\n","    m, b  = 0, 0                              \n","    layer_count = [0, 0, 0]                                       # layers in [div, child, blocks]\n","    block_count = [0, 0]                                          # blocks in [div, childs]\n","    frozen_count=[[0,0], [0, 0], [0,0]]                           # [Frozen, Unfrozen] layers in [div, child, blocks],  \n","\n","    # 2.iterate over rows, incrementing counters with each new row\n","    for row in df.itertuples():\n","      idx = row.Index\n","      if row.Currently == 'Frozen':\n","        for i in [0,1,2]: frozen_count[i][0] += 1 \n","      if row.Currently == 'Unfrozen':\n","        for i in [0,1,2]: frozen_count[i][1] += 1\n","      if row.Layer_description != '':\n","        for i in [0,1,2]: layer_count[i] += 1 \n","\n","      # backfill 'child' container rows with layer_info and block and layer counts\n","      if (row.Output_dimensions == '' and row.Container_child != '') or row.Module_name == '1':\n","        m = idx if m == 0 else m\n","        df.at[m, 'out_dim'] = df.at[idx-1, 'Output_dimensions']\n","        df.at[m, ['current', 'blk_chd', 'lyr_chd']] = self.get_frozen(frozen_count[1]), block_count[1], layer_count[1] \n","        m = idx\n","        layer_count[1] = block_count[1] = 0\n","        for i in [0, 1]: frozen_count[1][i] = 0\n","\n","      # backfill 'block' container rows with layer_info and layer counts\n","      if (row.Output_dimensions == '' and row.Container_block != '') or row.Module_name == '1':\n","        b = idx if b == 0 else b\n","        df.at[b, 'out_dim'] = df.at[idx-1, 'Output_dimensions'] or df.at[idx-2, 'Output_dimensions']  \n","        df.at[b, ['current', 'lyr_blk']] = self.get_frozen(frozen_count[2]), layer_count[2]\n","        b = idx\n","        layer_count[2] = 0\n","        for i in [0, 1]: block_count[i] += 1\n","        for i in [0, 1]: frozen_count[2][i] = 0\n","      \n","    # 3.backfill division container rows with summary layer_info and block and layer counts\n","    div0_idx = df[df['Module_name'] == '0'].index.tolist()[0]\n","    div1_idx = df[df['Module_name'] == '1'].index.tolist()[0] \n","\n","    df.at[div0_idx, 'out_dim'] = df.at[div1_idx-1, 'Output_dimensions'] or df.at[div1_idx-2, 'Output_dimensions']  \n","    df.at[div0_idx, ['current', 'lyr_chd', 'blk_chd']] = self.get_frozen(frozen_count[0]), layer_count[0], block_count[0]\n","\n","    df.at[div1_idx, 'out_dim'] = df.iloc[-1]['Output_dimensions']\n","\n","    self._cndf = df\n","\n","  @staticmethod\n","  def get_frozen(f):\n","    \"Returns a string interpretation of the number of frozen/unfrozen layers in tuple `f`\"\n","    if f[0] == 0: return 'Unfrozen'\n","    elif f[1] == 0: return 'Frozen'\n","    else: return f'{f[0]}/{(f[0]+f[1])} layers frozen'\n","\n","  @property\n","  def output_dimensions(self):\n","    \"Returns output dimensions of model (bs, classes)\"\n","    return self._cndf.iloc[-1]['Output_dimensions']\n","\n","  @property\n","  def frozen_to(self):\n","    \"Returns parameter group model is curently frozen to\"\n","    return self.learner.opt.frozen_idx + 1\n","\n","  @property\n","  def num_param_groups(self):\n","    \"Returns number of parameter groups\"\n","    return len(self.learner.opt.param_groups)\n","\n","  @property\n","  def batch_size(self):\n","    \"Returns the batch size of the current learner\"\n","    return self.bs\n","\n","  @property\n","  def input_sizes(self):\n","    \"Returns the sizes (dimensions bs, ch, h, w) of the model)\"\n","    return self.inp_sz\n","\n","  @property\n","  def model_info(self):\n","    \"Return an info string derived from`Learner.model`\"  \n","    res = f\"{self.model_type.capitalize()}: {self.model_name.capitalize()}\\n\"\n","    res += f\"Input shape: [{self.inp_sz}] (bs, ch, h, w)\\n\"\n","    res += f\"Output features: {self.output_dimensions} (bs, classes)\\n\" \n","    res += f\"Currently frozen to parameter group {self.frozen_to} out of {self.num_param_groups}\" \n","    return res\n","\n","  def cndf(self, with_modules=False):\n","    \"Returns a ConvNav dataframe\"\n","    df = self._cndf.copy() \n","    if not with_modules: df = df.iloc[:,:-1]\n","    return df\n","\n","  def layer_params(self, idx):\n","    \"Returns the parameters of layer with Index `idx`\"\n","    m = get_layer(self._cndf, idx)\n","    assert not m_out is None, f'Module {idx} is a container module, not a layer'\n","    return int(m['Parameters'].replace(',', ''))\n","\n","  def layer_dims(self, idx):\n","    \"Return tuple of input and output dimensions (as strings) of layer with index `idx`\"\n","    m_out = get_layer(self._cndf, idx)\n","    assert not m_out is None, f'Module {idx} is a container module, not a layer'\n","    i = 1\n","    m_in = None\n","    while m_in is None:\n","      m_in = get_layer(self._cndf, idx-i)\n","      i += 1\n","      if idx-i == 0:\n","        break\n","    return (self.inp_sz if m_in is None else m_in['Output_dimensions'], m_out['Output_dimensions'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eQg4phUqR2JX","colab_type":"text"},"source":["CNDF class builds a dataframe using a fastai Learner and the output of Learner.summary() method. The resulting dataframe, called a CNDF dataframe, combines information from both sources and represents both the structure and information of Learner.model. \n","\n","CNDF is a parent class of ConvNav and a CNDF dataframe is automatically built when a new ConvNav object is instantiated and for most use cases CNDF dataframes should be built this way. However, if there is a need to build a CNDF dataframe in isolation use: \n","\n","```\n","cndf = CNDF(Learner, Learner.summary())\n","```\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ggQd76o0GXB7","colab":{}},"source":["test_learner, test_summary, _ = get_test_vars()\n","cndf_test = CNDF(test_learner, test_summary)\n","\n","test_eq(type(cndf_test._cndf), DataFrame)   \n","test_eq(len(cndf_test._cndf), 79)             # rows\n","test_eq(len(cndf_test._cndf.columns), 22)     # columns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Imu1eLoRtg2","colab_type":"code","outputId":"2dd534ed-a83d-4fc3-9236-b0b10b353e89","executionInfo":{"status":"ok","timestamp":1582211425276,"user_tz":300,"elapsed":26426,"user":{"displayName":"Mathew Hall","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBa8oE_AN_QEPE85hyc_KMTdjOhShsUElZWGAQusQ=s64","userId":"18281963832597335062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["show_doc(CNDF.cndf)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h4 id=\"CNDF.cndf\" class=\"doc_header\"><code>CNDF.cndf</code><a href=\"__main__.py#L124\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>CNDF.cndf</code>(**`with_modules`**=*`False`*)\n\nReturns a ConvNav dataframe","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"pTUNAtwptLdh","colab_type":"text"},"source":["In native format, CNDF dataframes include the module objects in a 'lyr_obj' column and the combined size of the module objects can be quite large, 100-200mb for a complex model such as a densenet or xresnet. Thus, by default, module objects are removed from the dataframe. Set `with_modules = True` to include module objects. in returned dataframe."]},{"cell_type":"code","metadata":{"id":"fh3eo5h5OTnH","colab_type":"code","outputId":"250ef956-94d0-44bd-f6cf-fbf857c5854f","executionInfo":{"status":"ok","timestamp":1582211425416,"user_tz":300,"elapsed":26556,"user":{"displayName":"Mathew Hall","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBa8oE_AN_QEPE85hyc_KMTdjOhShsUElZWGAQusQ=s64","userId":"18281963832597335062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["show_doc(CNDF.batch_size)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h4 id=\"CNDF.batch_size\" class=\"doc_header\"><code>CNDF.batch_size</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturns the batch size of the current learner","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0AsADKEDOTEi","colab_type":"code","outputId":"3df418e8-a197-408e-974b-00eea70fd873","executionInfo":{"status":"ok","timestamp":1582211425418,"user_tz":300,"elapsed":26551,"user":{"displayName":"Mathew Hall","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBa8oE_AN_QEPE85hyc_KMTdjOhShsUElZWGAQusQ=s64","userId":"18281963832597335062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["show_doc(CNDF.input_sizes)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h4 id=\"CNDF.input_sizes\" class=\"doc_header\"><code>CNDF.input_sizes</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturns the sizes (dimensions bs, ch, h, w) of the model)","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Q_vdsu3hMDsN","colab_type":"code","outputId":"f5ad5838-e0d9-4f70-923d-cc32e75cc833","executionInfo":{"status":"ok","timestamp":1582211425419,"user_tz":300,"elapsed":26546,"user":{"displayName":"Mathew Hall","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBa8oE_AN_QEPE85hyc_KMTdjOhShsUElZWGAQusQ=s64","userId":"18281963832597335062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["show_doc(CNDF.output_dimensions)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h4 id=\"CNDF.output_dimensions\" class=\"doc_header\"><code>CNDF.output_dimensions</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturns output dimensions of model (bs, classes)","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"g6I1dpHZMRdJ","colab_type":"code","outputId":"ff5c6bf5-c257-49ba-b45d-2d39cdb6b0bc","executionInfo":{"status":"ok","timestamp":1582211425821,"user_tz":300,"elapsed":26941,"user":{"displayName":"Mathew Hall","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBa8oE_AN_QEPE85hyc_KMTdjOhShsUElZWGAQusQ=s64","userId":"18281963832597335062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["show_doc(CNDF.model_info)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h4 id=\"CNDF.model_info\" class=\"doc_header\"><code>CNDF.model_info</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturn an info string derived from`Learner.model`","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9AcNnv5GRo4Y","colab_type":"code","outputId":"c886b09d-d9d8-41d8-8f1e-797824ec783b","executionInfo":{"status":"ok","timestamp":1582211425822,"user_tz":300,"elapsed":26934,"user":{"displayName":"Mathew Hall","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBa8oE_AN_QEPE85hyc_KMTdjOhShsUElZWGAQusQ=s64","userId":"18281963832597335062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["show_doc(CNDF.layer_params)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h4 id=\"CNDF.layer_params\" class=\"doc_header\"><code>CNDF.layer_params</code><a href=\"__main__.py#L130\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>CNDF.layer_params</code>(**`idx`**)\n\nReturns the parameters of layer with Index `idx`","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"vtE66fqeRoVx","colab_type":"code","outputId":"4592065a-9032-4e01-8c93-71479831a5eb","executionInfo":{"status":"ok","timestamp":1582211425824,"user_tz":300,"elapsed":26929,"user":{"displayName":"Mathew Hall","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBa8oE_AN_QEPE85hyc_KMTdjOhShsUElZWGAQusQ=s64","userId":"18281963832597335062"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["show_doc(CNDF.layer_dims)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/markdown":"<h4 id=\"CNDF.layer_dims\" class=\"doc_header\"><code>CNDF.layer_dims</code><a href=\"__main__.py#L136\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>CNDF.layer_dims</code>(**`idx`**)\n\nReturn tuple of input and output dimensions (as strings) of layer with index `idx`","text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"T1HVvfdeH9dF","colab_type":"text"},"source":["## Element selectors"]},{"cell_type":"code","metadata":{"id":"6QJocZ2OI1xU","colab_type":"code","colab":{}},"source":["#export\n","def get_layer(df, idx):\n","  \"Returns layer with Index `idx` from CNDF dataframe `df` or `None` if `idx` indexes a container element and an exception if `idx` is invalid.\" \n","  if isinstance(idx, int): \n","    if 0 < idx < len(df):\n","      m = df.iloc[idx]\n","      if m['Layer_description'] in {'', '. . ContainerConvLayer', 'ContainerSequential'}:\n","        return None\n","      else: return m\n","    else: \n","      assert True, 'Index out of range.'\n","  assert True, 'Invalid index'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsxlC2ebTYp4","colab_type":"code","colab":{}},"source":["_, _, cndf_test = get_test_vars()\n","test_eq(get_layer(cndf_test, 2)['Module_name'], '0.0')\n","test_eq(get_layer(cndf_test, 1), None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"liuBs57AJQI8","colab_type":"code","colab":{}},"source":["#hide\n","try:\n","  get_layer(cndf_test, \"2\")\n","  get_layer(cndf_test, 100)\n","  assert True, 'Failed: get_layer() accepted invalid arguments'\n","except:\n","  pass"],"execution_count":0,"outputs":[]}]}
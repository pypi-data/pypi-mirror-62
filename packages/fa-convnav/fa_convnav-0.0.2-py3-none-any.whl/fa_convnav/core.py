# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['find_model', 'get_row', 'supported_models', 'get_inp_sz', 'infos_to_gen', 'CNDF', 'get_layer']

# Cell
import gzip, pickle
from dataclasses import dataclass
from pandas import DataFrame, option_context
from .models import models

# Cell
def find_model(n):
    "Returns tuple of model type and name (e.g. ('resnet', 'resnet50')) given `n`, the number of named_modules in Learner.model.named_modules()"
    for d in models:
      match = [(k, m) for k, v in d.items() for m, l in v if l == n]
      if match != []: break
    if len(match) > 0: return match[0] # (model_type, model_name)
    assert True, 'Model not supported. Use `supported_models()` to get a list of supported models.'

# Cell
def get_row(l, m):
  "Construct dataframe row from `l` (Learner.named_modules() module) and `m` (model_type)"

  # create generic row data from `l` (model.named_module() layer) and `m` (model_type)
  lyr_name = l[0]
  lyr_obj = l[1]
  ln_split = str(lyr_name).split('.', 4)
  ln_n_splits = len(ln_split)
  lyr_str = str(lyr_obj)

  tch_cls_str = str(type(lyr_obj))
  tch_cls_substr =  tch_cls_str[tch_cls_str.find("<class")+8: tch_cls_str.find(">")-1]
  tch_cls = tch_cls_substr.split('.')[-1]

  div = tch_cls if lyr_name == '0' or lyr_name == '1' else ''
  mod = tch_cls if ln_n_splits == 2 else ''
  blk = tch_cls if ln_n_splits == 3 and not lyr_name.startswith('1') else ''
  lyr = lyr_str[:90]

  # customise generic row for peculiarities of specific models
  if m == 'vgg' or m == 'alexnet':
    if ln_n_splits >2: ln_split[2] = ''
    blk = ''

  elif m == 'squeezenet':
     blk = tch_cls if ln_n_splits == 3 and tch_cls == 'Fire' else ''
     if blk == 'Fire': lyr = ''

  elif m == 'resnet':
    if blk == 'BasicBlock' or blk == 'Bottleneck': lyr = ''
    else:
      if ln_n_splits > 4: lyr = f". . {lyr_str[:86]}"
      if ln_n_splits == 4 and ln_split[3] == 'downsample': lyr = f'Container{tch_cls}'

  elif m == 'densenet':
    lyr_name = lyr_name.replace('denseblock', '').replace('denselayer', '')
    ln_split = str(lyr_name).split('.', 5)
    if len(ln_split) > 1 and ln_split[0] != '1': del ln_split[1]
    ln_n_splits = len(ln_split)

    mod = tch_cls if (lyr_name.startswith('0') and ln_n_splits == 2) or (lyr_name.startswith('1') and ln_n_splits == 2) else ''
    blk = tch_cls if ln_n_splits == 3 and tch_cls == '_DenseLayer' else ''
    if mod == '_DenseBlock' or mod == '_Transition' or blk == '_DenseLayer':
      lyr = ''
    else:
      if lyr_name == '0' or lyr_name == '1': div = tch_cls
      if lyr_name == '0.0': div = f'. . {tch_cls}'

  elif m == 'xresnet':
    blk = tch_cls if ln_n_splits == 3 and tch_cls == 'ResBlock' else ''
    if mod == 'ConvLayer' or blk == 'ResBlock':
      lyr = ''
    else:
      if ln_n_splits < 4: lyr =  lyr_str[:90]
      elif ln_n_splits == 4 and tch_cls == 'Sequential': lyr =  f'Container{tch_cls}'
      elif ln_n_splits == 4 and tch_cls == 'ReLU': lyr =  lyr_str[:90]
      elif ln_n_splits == 5 and tch_cls == 'ConvLayer': lyr =  f'. . Container{tch_cls}'
      else: lyr =  f'. . . . {lyr_str[:32]}'

  else:
    raise Exception("Model type not recognised")

  return {
      'Module_name': lyr_name,
      'Model': tch_cls if lyr_name == '' else '',
      'Division': div,
      'Container_child': mod,
      'Container_block': blk,
      'Layer_description': lyr,
      'Torch_class': tch_cls_substr,
      'Output_dimensions': '',
      'Parameters': '',
      'Trainable': '',
      'Currently': '',
      'div_id': ln_split[0] if ln_n_splits >0 else '',
      'chd_id': ln_split[1] if ln_n_splits >1 else '',
      'blk_id': ln_split[2] if ln_n_splits >2 else '',
      'lyr_id': ln_split[3] if ln_n_splits >3 else '',
      'tch_cls': tch_cls,
      'out_dim': '',
      'current': '',
      'lyr_blk': '',
      'lyr_chd': '',
      'blk_chd': '',
      'lyr_obj': lyr_obj
      }

# Cell
def supported_models():
  "Prints list of models supported by fa_convnav (models.ipynb contains list of currently supported models)."
  print('Supported models')
  print('================\n')
  for d in models:
      [[print(m) for m, l in v] for k, v in d.items()]

# Cell
def get_inp_sz(infos):
  "Slice first row of `infos` to give string representation of model input sizes "
  inp_sz = infos[0]
  inp_sz_str = inp_sz[inp_sz.find("['")+2:inp_sz.find("']")]
  return inp_sz_str

# Cell
def infos_to_gen(infos):
  "Slice the remaining rows of `infos` to give the layers, `m`, output dimensions `o`, parameters `p`, and trainable `t` of each layer and return (m,o,p,t) for all layers in a generator"
  lyr_info = infos[4:-17][::2]
  info_list = []
  for l in lyr_info:
    m, *s, p, t = [y for y in l.split(' ') if y !=""]
    info_list.append((m, f"[{' '.join(s)}]", p, t))
  return (i for i in info_list)

# Cell
@dataclass
class CNDF:
  "Compile information from fastai `Learner.model` and 'layer_info(Learner)` into a dataframe"
  learner: any
  learner_summary: str

  def __post_init__(self):
    assert hasattr(self.learner, 'model'), "Invalid learner: no 'model' attribute"
    self.model = self.learner.model                                         # fastai `Learner.model` object
    self.layers = list(self.learner.model.named_modules())                  # fastai `named_modules` method
    self.num_layers = len(self.layers)
    self.model_type, self.model_name = find_model(self.num_layers)

    infos_split = self.learner_summary.split('\n')                         # fastai `Learner.summary()` string
    self.inp_sz = get_inp_sz(infos_split)
    self.bs = self.inp_sz[0]
    info_gen = infos_to_gen(infos_split)

    # create base dataframe `df` from a list of formatted rows in `layers`
    df = DataFrame([get_row(l, self.model_type) for l in self.layers])

    # remove layer descriptions from container rows
    df.at[0, 'Layer_description'] = ''
    df.loc[(df['Division'].str.contains('Sequential')) | \
          (df['Container_child'] == 'Sequential') | \
          (df['Container_child'] == 'AdaptiveConcatPool2d'), 'Layer_description'] = ''

    for row in df.itertuples():
      idx = row.Index
      if row.Layer_description not in {'', '. . ContainerConvLayer', 'ContainerSequential'}:
        _, o, p, t = next(info_gen)
        df.at[idx, 'Output_dimensions'] = str(o)
        df.at[idx, 'Parameters'] =  p
        df.at[idx, 'Trainable'] = t
        if 'Conv2d' in row.Torch_class:
          df.at[idx, 'Currently'] = 'Unfrozen' if t == 'True' else 'Frozen'

    # backfill container rows with summary layer information and layer/block counts
    # 1.set up index stores and counters
    m, b  = 0, 0
    layer_count = [0, 0, 0]                                       # layers in [div, child, blocks]
    block_count = [0, 0]                                          # blocks in [div, childs]
    frozen_count=[[0,0], [0, 0], [0,0]]                           # [Frozen, Unfrozen] layers in [div, child, blocks],

    # 2.iterate over rows, incrementing counters with each new row
    for row in df.itertuples():
      idx = row.Index
      if row.Currently == 'Frozen':
        for i in [0,1,2]: frozen_count[i][0] += 1
      if row.Currently == 'Unfrozen':
        for i in [0,1,2]: frozen_count[i][1] += 1
      if row.Layer_description != '':
        for i in [0,1,2]: layer_count[i] += 1

      # backfill 'child' container rows with layer_info and block and layer counts
      if (row.Output_dimensions == '' and row.Container_child != '') or row.Module_name == '1':
        m = idx if m == 0 else m
        df.at[m, 'out_dim'] = df.at[idx-1, 'Output_dimensions']
        df.at[m, ['current', 'blk_chd', 'lyr_chd']] = self.get_frozen(frozen_count[1]), block_count[1], layer_count[1]
        m = idx
        layer_count[1] = block_count[1] = 0
        for i in [0, 1]: frozen_count[1][i] = 0

      # backfill 'block' container rows with layer_info and layer counts
      if (row.Output_dimensions == '' and row.Container_block != '') or row.Module_name == '1':
        b = idx if b == 0 else b
        df.at[b, 'out_dim'] = df.at[idx-1, 'Output_dimensions'] or df.at[idx-2, 'Output_dimensions']
        df.at[b, ['current', 'lyr_blk']] = self.get_frozen(frozen_count[2]), layer_count[2]
        b = idx
        layer_count[2] = 0
        for i in [0, 1]: block_count[i] += 1
        for i in [0, 1]: frozen_count[2][i] = 0

    # 3.backfill division container rows with summary layer_info and block and layer counts
    div0_idx = df[df['Module_name'] == '0'].index.tolist()[0]
    div1_idx = df[df['Module_name'] == '1'].index.tolist()[0]

    df.at[div0_idx, 'out_dim'] = df.at[div1_idx-1, 'Output_dimensions'] or df.at[div1_idx-2, 'Output_dimensions']
    df.at[div0_idx, ['current', 'lyr_chd', 'blk_chd']] = self.get_frozen(frozen_count[0]), layer_count[0], block_count[0]

    df.at[div1_idx, 'out_dim'] = df.iloc[-1]['Output_dimensions']

    self._cndf = df

  @staticmethod
  def get_frozen(f):
    "Returns a string interpretation of the number of frozen/unfrozen layers in tuple `f`"
    if f[0] == 0: return 'Unfrozen'
    elif f[1] == 0: return 'Frozen'
    else: return f'{f[0]}/{(f[0]+f[1])} layers frozen'

  @property
  def output_dimensions(self):
    "Returns output dimensions of model (bs, classes)"
    return self._cndf.iloc[-1]['Output_dimensions']

  @property
  def frozen_to(self):
    "Returns parameter group model is curently frozen to"
    return self.learner.opt.frozen_idx + 1

  @property
  def num_param_groups(self):
    "Returns number of parameter groups"
    return len(self.learner.opt.param_groups)

  @property
  def batch_size(self):
    "Returns the batch size of the current learner"
    return self.bs

  @property
  def input_sizes(self):
    "Returns the sizes (dimensions bs, ch, h, w) of the model)"
    return self.inp_sz

  @property
  def model_info(self):
    "Return an info string derived from`Learner.model`"
    res = f"{self.model_type.capitalize()}: {self.model_name.capitalize()}\n"
    res += f"Input shape: [{self.inp_sz}] (bs, ch, h, w)\n"
    res += f"Output features: {self.output_dimensions} (bs, classes)\n"
    res += f"Currently frozen to parameter group {self.frozen_to} out of {self.num_param_groups}"
    return res

  def cndf(self, with_modules=False):
    "Returns a ConvNav dataframe"
    df = self._cndf.copy()
    if not with_modules: df = df.iloc[:,:-1]
    return df

  def layer_params(self, idx):
    "Returns the parameters of layer with Index `idx`"
    m = get_layer(self._cndf, idx)
    assert not m_out is None, f'Module {idx} is a container module, not a layer'
    return int(m['Parameters'].replace(',', ''))

  def layer_dims(self, idx):
    "Return tuple of input and output dimensions (as strings) of layer with index `idx`"
    m_out = get_layer(self._cndf, idx)
    assert not m_out is None, f'Module {idx} is a container module, not a layer'
    i = 1
    m_in = None
    while m_in is None:
      m_in = get_layer(self._cndf, idx-i)
      i += 1
      if idx-i == 0:
        break
    return (self.inp_sz if m_in is None else m_in['Output_dimensions'], m_out['Output_dimensions'])

# Cell
def get_layer(df, idx):
  "Returns layer with Index `idx` from CNDF dataframe `df` or `None` if `idx` indexes a container element and an exception if `idx` is invalid."
  if isinstance(idx, int):
    if 0 < idx < len(df):
      m = df.iloc[idx]
      if m['Layer_description'] in {'', '. . ContainerConvLayer', 'ContainerSequential'}:
        return None
      else: return m
    else:
      assert True, 'Index out of range.'
  assert True, 'Invalid index'
# AUTOGENERATED! DO NOT EDIT! File to edit: 20_utils.ipynb (unless otherwise specified).

__all__ = ['parallel', 'num_cpus', 'open_file', 'chunk_of_text', 'get_file_chunks']

# Cell
from .imports import *

from fastprogress.fastprogress import progress_bar
from concurrent.futures import ProcessPoolExecutor, as_completed


# Cell

# BEGIN From fastai
def parallel(func, arr, max_workers=-1):
    if max_workers == -1:
        max_workers = num_cpus(2)
    with ProcessPoolExecutor(max_workers=max_workers) as ex:
        futures = [ex.submit(func, arr_el) for arr_el in arr]
        results = []
        for f in progress_bar(as_completed(futures), total=len(arr)):
            results.append(f.result())
        return results

def num_cpus(n_cpus):
    try:
        return len(os.sched_getaffinity(0))
    except AttributeError:
        return os.cpu_count()
    if n_cpus > 0:
        return n_cpus
    """Get number of cpus."""
# END From fastai


def open_file(filepath, options):
    if filepath[-3:] == ".gz":
        return gzip.open(filepath, options)
    return open(filepath, options)


def chunk_of_text(_file, chunk_size=-1):
    index = 0
    if chunk_size == -1:
        chunk_size = 200
    while True:
        line = _file.readline()
        if not line:
            break
        for sentence in line.split("."):
            if sentence.strip():
                yield sentence.strip()
        if index >= chunk_size:
            break
        index += 1


def get_file_chunks(start_index, filepath, lines_chunk, sample_size):
    _file = open_file(filepath, 'rt')
    texts = []
    break_by_sample = False
    while True:
        next_n_lines = list(chunk_of_text(_file, lines_chunk))
        texts.append("\n".join(next_n_lines) + "\n")
        if not next_n_lines:
            break
        start_index += lines_chunk
        if sample_size > 0 and start_index >= sample_size:
            break_by_sample = True
            break
    _file.close()
    return (start_index, texts, break_by_sample)

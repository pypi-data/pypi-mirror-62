# AUTOGENERATED! DO NOT EDIT! File to edit: 30_main.ipynb (unless otherwise specified).

__all__ = ['tokenize_file', 'train_model', 'similars_tree_from_model', 'get_similars', 'similars_tree']

# Cell
from .imports import *

from glob import glob
from functools import partial

import fasttext

from .utils import parallel, open_file, chunk_of_text, get_file_chunks
from .tokenizer import tokenize

# Cell

def tokenize_file(
    input_path, output_path="tokenized.txt", lang="en",
    sample_size=-1, lines_chunks=-1, n_cpus=-1, keywords_w_stopwords=False
):
    tokenize_wrapper = partial(
        tokenize, lang=lang, text_output=True, merge=True, keywords_w_stopwords=keywords_w_stopwords
    )

    index = 0

    with open(output_path, "wt") as _output:
        for file_path in glob(input_path):
            print("processing file:", file_path)
            # We are going to split the text in chunks to show some progress.
            new_index, text_chunks, break_by_sample = get_file_chunks(index, file_path, lines_chunks, sample_size)
            index = new_index
            results = parallel(tokenize_wrapper, text_chunks, n_cpus)
            _output.write(
                ("\n".join(results) + "\n").replace(" ", "_").replace("!", " ")
            )
            if break_by_sample:
                break
    return output_path


def train_model(input_filename):
    model = fasttext.train_unsupervised(input_filename, model='skipgram', maxn=0, dim=100, ws=5)
    return model

def similars_tree_from_model(model, vector_size=100):
    f = 100
    t = AnnoyIndex(f, 'angular')  # Length of item vector that will be indexed
    labels = model.labels
    for index, label in enumerate(labels):
        v = model[label]
        t.add_item(index, v)

    t.build(10) # 10 trees
    return labels, t

def get_similars(tree, labels, keyword, n_similars=10, show_score=False):
    index = labels.index(keyword.replace(" ", "_"))
    suggestions, scores = tree.get_nns_by_item(index, n=15, include_distances=True)
    suggested_labels = [
        labels[suggestion].replace("_", " ")
        for suggestion in suggestions
    ]
    return suggested_labels

def similars_tree(
    input_path, temp_tokenized_file="tmp_tokenized.txt", lang="en",
    sample_size=-1, lines_chunks=-1, n_cpus=-1, keywords_w_stopwords=False
):
    tokenize_file(
        input_path=input_path, output_path=temp_tokenized_file, lang=lang,
        sample_size=sample_size, lines_chunks=lines_chunks, n_cpus=n_cpus,
        keywords_w_stopwords=keywords_w_stopwords
    )
    model = train_model(temp_tokenized_file)
    labels, tree = similars_tree_from_model(model)
    return labels, tree
